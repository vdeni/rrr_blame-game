---
output:
    word_document
---

```{r setup, echo=F, message=F, warning=F, results='hide'}
library(here)

setwd(here::here('analyses'))

renv::activate()

library(dplyr)
library(magrittr)
library(ggplot2)
library(tidyr)

knitr::opts_chunk$set(device = 'png',
                      dpi = 300,
                      echo = F,
                      message = F,
                      fig.height = 8,
                      fig.width = 8 * 9 / 16)

options(scipen = 5,
        digits = 3)

.fine_lim_hrk <- 10200
.fine_lim_usd <- 4500

ggplot2::theme_set(theme_minimal())

ggplot2::theme_update(strip.background = ggplot2::element_rect(fill = 'grey'),
                      panel.spacing.y = unit(x = 20,
                                             units = 'pt'))

source(here('analyses',
            'helpers',
            'helpers_plot.R'))
```

# Analyses

## Study 1a

```{r s1a-load-data}
source(here::here('analyses',
                  'study_1a',
                  'wrangling',
                  'study_1a_prepare-analysis-data.R'))
```

```{r s1a-plot-assessments, fig.cap='Individual responses to the proposed fine and stated level of blame (jittered horizontally). The X-es represent each group\'s mean value.'}
.p_data <- d_s1a %>%
    tidyr::pivot_longer(.,
                        cols = c('assess_fine',
                                 'assess_blame'),
                        names_pattern = 'assess_(\\w+)',
                        names_to = 'assessment',
                        values_to = 'value')


.summary <- dplyr::group_by(.p_data,
                            assessment,
                            experimental_situation) %>%
    dplyr::summarise(.,
                     m = mean(value))

s1Plot(.p_data,
       .summary)
```

The groups that read the agentive and the nonagentive description of the
event were compared on the amount fined and blame level assessment using a
one-sided t-test. Following the findings of the original study, we assumed
that reading the agentive description of the event would lead to a higher
fine and higher assessed blame level; this direction was also posited in the
one-sided t-tests. Also, as a manipulation check, participants were asked to
rate the extent to which the subject of the described event played an active
role in starting the fire. Groups were compared on those assessments using
a two-sided t-test.

```{r s1a-t-test}
t_active <- t.test(assess_active_role ~ experimental_situation,
                   d_s1a,
                   alternative = 'two.sided',
                   var.equal = T,
                   paired = F,
                   confidence.interval = .95)

t_fine <- t.test(assess_fine ~ experimental_situation,
                 d_s1a,
                 alternative = 'greater',
                 var.equal = T,
                 paired = F,
                 confidence.interval = .95)

t_blame <- t.test(assess_blame ~ experimental_situation,
                  d_s1a,
                  alternative = 'greater',
                  var.equal = T,
                  paired = F,
                  confidence.interval = .95)
```

Comparing the assessment of the subject's activity,
we obtain a t-test that is significant at the .05 level
($\Delta_{ag-nonag} = `r t_active$estimate[1] - t_active$estimate[2]`,
t(`r t_active$parameter`) = `r t_active$statistic`,
p = `r t_active$p.value`,
95\% \text{CI} = [`r t_active$conf.int[1]`, `r t_active$conf.int[2]`]$)

Comparing the amounts fined by the two groups, we obtain a t-test that is not
significant at the .05 level
($\Delta_{ag-nonag} = `r t_fine$estimate[1] - t_fine$estimate[2]` \text{HRK},
t(`r t_fine$parameter`) = `r t_fine$statistic`,
p = `r t_fine$p.value`,
95\% \text{CI} = [`r t_fine$conf.int[1]`, `r t_fine$conf.int[2]`]$)

Comparing the level of blame assessed by the two groups, we obtain a t-test
that is significant at the .05 level
($\Delta_{ag-nonag} = `r t_blame$estimate[1] - t_blame$estimate[2]`,
t(`r t_blame$parameter`) = `r t_blame$statistic`,
p = `r t_blame$p.value`,
95\% \text{CI} = [`r t_blame$conf.int[1]`, `r t_blame$conf.int[2]`]$)

## Study 1b

```{r s1b-load-data}
source(here::here('analyses',
                  'study_1b',
                  'wrangling',
                  'study_1b_prepare-analysis-data.R'))
```

```{r s1b-plot-assessments, fig.cap='Individual responses to the proposed fine and stated level of blame (jittered horizontally). The X-es represent each group\'s mean value.'}
.p_data <- d_s1b %>%
    tidyr::pivot_longer(.,
                        cols = c('assess_fine',
                                 'assess_blame'),
                        names_pattern = 'assess_(\\w+)',
                        names_to = 'assessment',
                        values_to = 'value')


.summary <- dplyr::group_by(.p_data,
                            assessment,
                            experimental_situation) %>%
    dplyr::summarise(.,
                     m = mean(value))

s1Plot(.p_data,
       .summary)
```

The groups that read the agentive and the nonagentive description of the
event were compared on the amount fined and blame level assessment using a
one-sided t-test. Following the findings of the original study, we assumed
that reading the agentive description of the event would lead to a higher
fine and higher assessed blame level; this direction was also posited in the
one-sided t-tests.

```{r s1b-t-test}
t_active <- t.test(assess_active_role ~ experimental_situation,
                   d_s1b,
                   alternative = 'two.sided',
                   var.equal = T,
                   paired = F,
                   confidence.interval = .95)

t_fine <- t.test(assess_fine ~ experimental_situation,
                 d_s1b,
                 alternative = 'greater',
                 var.equal = T,
                 paired = F,
                 confidence.interval = .95)

t_blame <- t.test(assess_blame ~ experimental_situation,
                  d_s1b,
                  alternative = 'greater',
                  var.equal = T,
                  paired = F,
                  confidence.interval = .95)
```

Comparing the assessment of the subject's activity,
we obtain a t-test that is significant at the .05 level
($\Delta_{ag-nonag} = `r t_active$estimate[1] - t_active$estimate[2]`,
t(`r t_active$parameter`) = `r t_active$statistic`,
p = `r t_active$p.value`,
95\% \text{CI} = [`r t_active$conf.int[1]`, `r t_active$conf.int[2]`]$)

Comparing the amounts fined by the two groups, we obtain a t-test that is
significant at the .05 level
($\Delta_{ag-nonag} = `r t_fine$estimate[1] - t_fine$estimate[2]` \text{USD},
t(`r t_fine$parameter`) = `r t_fine$statistic`,
p = `r t_fine$p.value`,
95\% \text{CI} = [`r t_fine$conf.int[1]`, `r t_fine$conf.int[2]`]$)

Comparing the level of blame assessed by the two groups, we obtain a t-test
that is significant at the .05 level
($\Delta_{ag-nonag} = `r t_blame$estimate[1] - t_blame$estimate[2]`,
t(`r t_blame$parameter`) = `r t_blame$statistic`,
p = `r t_blame$p.value`,
95\% \text{CI} = [`r t_blame$conf.int[1]`, `r t_blame$conf.int[2]`]$)

## Study 2a

```{r s2a-load-data}
source(here::here('analyses',
                  'study_2a',
                  'wrangling',
                  'study_2a_prepare-analysis-data.R'))
```

```{r s2a-plot-assessments, fig.cap='Individual responses to the proposed fine and stated level of blame (jittered horizontally). The X-es represent each group\'s mean value.'}
.summary <- dplyr::group_by(d_s2a,
                            agency,
                            blame_level) %>%
    dplyr::summarise(.,
                     m = mean(assess_fine))

s2Plot(d_s2a,
       .summary)
```

## Study 2b
